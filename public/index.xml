<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lucas Bagge</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Lucas Bagge</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Lucas Bagge, 2023</copyright><lastBuildDate>Thu, 07 Jan 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/sharing_image.jpg</url>
      <title>Lucas Bagge</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Cargo classification</title>
      <link>/post/cargo-classification/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/post/cargo-classification/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Amagerværket has two units 1 and 4 which produces heat and power using
respectively wood pellets and wood chips as fuel. The fuel arrives to the plant
by vessel and it is possible to track the arrivals through Copenhagen Malmö (CM)
Port&amp;rsquo;s website. However, it is not directly possible to identify if the cargo of
a given ship is either wood pellets or wood chips. Consequently, the objective
is to build a model capable of classifying the vessels.&lt;/p&gt;
&lt;p&gt;With the newly inaugurated wood chips fired unit 4 at Amagerværket and
expectedly using well above 1 Mt of wood chips per year, the plant has
suddenly&amp;mdash;and by a substantial margin&amp;mdash;become the largest player in the market
for wood chips delivered by vessel. To maintain market visibility and have the
best possible information to act in the biomass market, it is of importance to
BIO Markets to have information about the arrival and consumption of biomass at
Amagerværket.&lt;/p&gt;
&lt;p&gt;The objective of this analysis is&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;build a model that accurately and automatically classify vessels arriving to
Amagerværket into groups according to cargo type&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;the-data-set&#34;&gt;The data set&lt;/h2&gt;
&lt;p&gt;For building our model we need to collect the 
&lt;a href=&#34;https://www.cmport.com/terminals/ships-in-port/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cmport
data&lt;/a&gt;
. Here we have used web
scraping techniques to extract the data that is essential for us to build our
model.&lt;/p&gt;
&lt;p&gt;The site is being updated on a regular basis, so our script that scrapes the
data is running three times a day.&lt;/p&gt;
&lt;p&gt;As a first analysis task we need to collect information about the port and if
there were information on how we could classify the cargoes. We got great insight
from colleagues that have tracked the cargoes for a long time and they gave us
the information that &lt;code&gt;quay&lt;/code&gt;, and &lt;code&gt;arriving from&lt;/code&gt; could help us
differentiated between the cargoes.&lt;/p&gt;
&lt;p&gt;We need to explore the data for understanding it better and look at the outcome
variable and the predictor we are considering being of most used for us.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gross_feature_set %&amp;gt;% kbl() %&amp;gt;% kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; feature &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; description &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; eta &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Estimated time of arrival &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; etd &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Estimated time of departure &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; name &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Vessel name &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; company &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The shipping company carrying out the charter &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The location from the vessel is arriving (not necessarily the loading port) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; nationality &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The country under whose laws the vessel is registered or licensed &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; vessel_type &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The types os the vessel arriving &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; purpose &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Give us the purpose of the vessel &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; call_no &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; CM Port call number &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; length &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Length of the vessel &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; width &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Width of the vessel &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; brt &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Gross Register Tonnage (GRT) of the vessel &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; imo &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The international Maritime Organization number &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; The quay at Amagerværket to which the vessel is assigned &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The available dataset consists of &lt;code&gt;\(N = 129\)&lt;/code&gt;
observations of vessel arrivals&amp;mdash;also named port calls or just calls&amp;mdash;to
Amagerværket each with 129 features. In the
current context not every feature is important, but those deemed important for
our model are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cargo&lt;/code&gt;: Specifies if the vessel carries wood chips (WC) or wood pellets (WP)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arriving_from&lt;/code&gt;: The port/city where the cargo is being loaded&lt;/li&gt;
&lt;li&gt;&lt;code&gt;quay&lt;/code&gt;: The quay at Amagerværket where the cargo is discharged&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;cargo&lt;/code&gt; variable is our outcome variable and the one we want to classify.&lt;/p&gt;
&lt;h3 id=&#34;the-cargo&#34;&gt;The cargo&lt;/h3&gt;
&lt;p&gt;Here we can see that there is 105 ships with WC and WP with 24. We don´t have an
equal amount of both cargoes and that is something that need to be considered in
the preprocessing step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vessels %&amp;gt;% 
  count(cargo) %&amp;gt;%   
  ggplot(aes(x = cargo, y = n, fill = cargo)) +
  geom_col() +
  geom_text(aes(label = n), nudge_y = 3) +
  labs(y = NULL, x = NULL,
       title = &amp;quot;Dependent variable based on cargo&amp;quot;,
       subtitle = &amp;quot;Number of cargoes containing either WP or WC&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-3-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;h3 id=&#34;the-quay-at-amagerværket&#34;&gt;The quay at Amagerværket&lt;/h3&gt;
&lt;p&gt;One important predictor is &lt;code&gt;quay&lt;/code&gt;. It indicate where the vessel anchor at the
port. Here we have four possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;c835&lt;/li&gt;
&lt;li&gt;c836&lt;/li&gt;
&lt;li&gt;c837&lt;/li&gt;
&lt;li&gt;c838&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tbl &amp;lt;- addmargins(table(vessels$cargo, vessels$quay))

tbl %&amp;gt;%
  as.data.frame() %&amp;gt;%
  pivot_wider(names_from = Var2, values_from = Freq) %&amp;gt;%
  kbl(col.names = c(&amp;quot;&amp;quot;, colnames(tbl)),
      caption = &amp;quot;Cross tabulation of cargo against quay.&amp;quot;) %&amp;gt;%
  kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From looking at the pattern in the data and talking to colleagues there is
some of the quay that is a clear indicator of if the vessel is a WP or WC.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vessels %&amp;gt;%
  count(quay) %&amp;gt;%
  ggplot(aes(x = quay, y = n, fill = quay)) +
  geom_col(position = &amp;quot;dodge&amp;quot;) +
  geom_text(aes(label = n), nudge_y = 3) +
  labs(y = NULL, x = NULL,
       title = &amp;quot;The Quay is a possible predictor&amp;quot;, 
       subtitle = &amp;quot;Number of cargoes arriving to the different quay&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-5-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Here &lt;code&gt;c838&lt;/code&gt; is the quay where WP is being delivered and &lt;code&gt;c836&lt;/code&gt; plus &lt;code&gt;c836&lt;/code&gt; is
mainly WC.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vessels %&amp;gt;% 
  count(quay, cargo) %&amp;gt;% 
  ggplot(aes(reorder_within(quay, n, cargo), n, fill = quay)) +
  facet_grid(rows = vars(cargo), scales = &#39;free_y&#39;) +
  geom_col(position = &amp;quot;dodge&amp;quot;) +
  geom_text(aes(label = n), nudge_y = 1.9) +
  coord_flip() +
  scale_x_reordered() +
  labs(title = &amp;quot;The quay indicate what the cargo is delivering&amp;quot;, 
       subtitle = &amp;quot;Number of cargoes arriving groped by WC or WP&amp;quot;,
       y = &amp;quot;&amp;quot;, x = &amp;quot;&amp;quot;) +
  theme(legend.title = element_blank())
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-6-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;From the above plots it is clear that we can from the quay seperat what the
vessel is delivering. For c837 this can be considered a joker. It lies between
the end quay, so our hypothesis is that it can be considered as a waiting
quay where it can either be WC or WP.&lt;/p&gt;
&lt;h3 id=&#34;the-loading-port-of-the-cargo&#34;&gt;The loading port of the cargo&lt;/h3&gt;
&lt;p&gt;Another important predictor we want to include in the models framework is
&lt;code&gt;arriving_from&lt;/code&gt;. This indicate where the vessel is comming from.
Here we want to make some investigation if we can use this as a predictor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vessels %&amp;gt;% 
  group_by(arriving_from, cargo) %&amp;gt;% 
  count(arriving_from, cargo)  %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(across(where(is.character), as.factor)) %&amp;gt;% 
  ggplot(aes(reorder_within(arriving_from, n, cargo), n, fill = cargo)) +
  geom_col(position = &amp;quot;dodge&amp;quot;) +
  geom_text(aes(label = n), nudge_y = 0.9) +
  facet_wrap(~cargo, scales = &amp;quot;free_y&amp;quot;) +
  coord_flip() +
  scale_x_reordered() +
  scale_fill_manual(values=c(&amp;quot;#4099DA&amp;quot;, &amp;quot;#E85757&amp;quot;)) + 
  labs(title = &amp;quot;Arrival port&amp;quot;,
       subtitle = &amp;quot;Number of cargoes grouped by arriving from&amp;quot;,
       y = &amp;quot;&amp;quot;, x = &amp;quot;&amp;quot;) +
  theme(legend.title = element_blank())
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-7-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt;
&lt;p&gt;For solving this supervised classifications task there is different models
that can be used and we did try out a logistic regression, KNN and decision tree
model. In the end we went with the logistic regression for classification.&lt;/p&gt;
&lt;p&gt;In the following section we want to work though the essentiel idea behind the
method.&lt;/p&gt;
&lt;h3 id=&#34;the-logistic-regression-model&#34;&gt;The logistic regression model&lt;/h3&gt;
&lt;p&gt;Logistic regression is a very popular model for classification problems and is
one of the most commonly used Machine Learning algorithms. It is easy
to implement and is often used in settings where the dataset is small or as a
baseline for any binary classification problem.&lt;/p&gt;
&lt;p&gt;The method is used when the outcome variable is dichotomous in nature. It is a
special case of the general linear regression model when the outcome variable is
binary.&lt;/p&gt;
&lt;p&gt;Let &lt;code&gt;\(y\)&lt;/code&gt; be our binary target with &lt;code&gt;\(y = 1\)&lt;/code&gt; if the vessel carries WC (the WC
class) and &lt;code&gt;\(y = 0\)&lt;/code&gt; if the cargo is WP (the WP class). Further, let &lt;code&gt;\(x\)&lt;/code&gt; be a
&lt;code&gt;\(M\)&lt;/code&gt;-vector of features of the observed port calls. Then, given some available
information &lt;code&gt;\(x\)&lt;/code&gt;, our interest lies in identifying the probability of a WC vessel
and by implication also the probability of a WP vessel. Hence,
$$
\Pr(y = 1 \mid x) = \pi^c(x) = 1 - \Pr(y = 0 \mid x) = 1 - \pi^p(x)
$$
where &lt;code&gt;\(\pi^c(x)\)&lt;/code&gt; and &lt;code&gt;\(\pi^p(x)\)&lt;/code&gt; are the conditional probabilities of observing
respectively a WC or a WP vessel. The probability mass function for this
Bernoulli distribution is
$$
p(y \mid x) = \pi^c(x) \cdot \bigl(1 - \pi^c(x)\bigr)^{1-y}.
$$&lt;/p&gt;
&lt;p&gt;In order to proceed from here, one has to make assumptions about the structure
of the probability &lt;code&gt;\(\pi^c(x)\)&lt;/code&gt;. The assumption used in the logistic regression
model is to proceed with a logistic function defined by
$$
\sigma(z) = \frac{1}{1 + \exp(-z)} = \frac{\exp(z)}{\exp(z) + 1},
$$
with
$$
z = \phi(x)&amp;rsquo; w
$$
and finally impose
$$
\pi^c(x) = \sigma(\phi(x)&amp;rsquo; w).
$$&lt;/p&gt;
&lt;p&gt;This equation tells that the crux of the logistic regression model is the
mapping of &lt;code&gt;\(z = \phi(x)&#39; w\)&lt;/code&gt; to a &amp;ldquo;probability&amp;rdquo; through the logistic function.&lt;/p&gt;
&lt;p&gt;The logistic function gives an S shape curvature. It takes any real vauled
number and map it into a value between 0 and 1. Here we have in mind of how the
probability should be interpreted. If we get an value 0.75 this mean that there
is 75 percent change that a cargo is WC (if WC is baseline).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;curve({exp(x) / (1 + exp(x))}, -10, 10, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;&amp;quot;,
      main = &amp;quot;The logistic function mapping z to the unit interval&amp;quot;)
abline(v = 0, lty = &amp;quot;dashed&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-8-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;For estimated the parameter logistic regression relies on Maximum likelihood
estimation (MLE). By this estimation technique the parameter is determined by
maximizing the log likelihood function. Here we need to use a optimization
algorithm for finding &lt;code&gt;\(w\)&lt;/code&gt;. Often one uses Gradient acent for this purpose.&lt;/p&gt;
&lt;p&gt;The coefficents should be read as log of odds so we predicts the probability of
occurrence of a binary event.&lt;/p&gt;
&lt;h2 id=&#34;analysis--results&#34;&gt;Analysis &amp;amp; results&lt;/h2&gt;
&lt;p&gt;For implement the logistic regression we are gonna use the software program &lt;code&gt;R&lt;/code&gt;
and it machine learning framework &lt;code&gt;tidymodels&lt;/code&gt;. tidymodels has its own unique way
of structuring a modelling problem and we follows that workflow.&lt;/p&gt;
&lt;h3 id=&#34;model-formulation-and-data-preprocessing&#34;&gt;Model formulation and data preprocessing&lt;/h3&gt;
&lt;p&gt;We split our data set in two sets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the &lt;em&gt;training set&lt;/em&gt;: This is the bigger part of the data which we use to
train/estimate of our models&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the &lt;em&gt;test set&lt;/em&gt;: This data we hold out to use for evaluation of our trained
models&lt;/p&gt;
&lt;p&gt;Further, we divide our training set into five folds to use for evaluation of
the models using cross-validation.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(4595)

df &amp;lt;- vessels %&amp;gt;% select(cargo, arriving_from, quay)
df_split &amp;lt;- initial_split(df, prop = 0.75, strata = cargo)
df_train &amp;lt;- training(df_split)
df_test &amp;lt;- testing(df_split)
df_train_folds &amp;lt;- vfold_cv(df_train, v = 5, strata = &amp;quot;cargo&amp;quot;) # FIXME 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Two model specifications are formulated. One where the cargo is predicted using
the quay, and one model where the cargo is predicted using the information about
the port where the vessel is arriving from.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fml_1 &amp;lt;- formula(cargo ~ quay)
fml_2 &amp;lt;- formula(cargo ~ arriving_from)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the prepoceesion step we gonna use &lt;code&gt;recipe&lt;/code&gt; which is part of tidymodels. Here
we gonna specify what we want to make of changes to the predictors and handling
other issues. In that step we also could implment a method for solving the
imbalanced dataset problem, but because it wont give a better result we don´t
add this step&#39;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_1_rec &amp;lt;-
  recipe(fml_1, data = df_train) %&amp;gt;% step_dummy(all_nominal(), -all_outcomes())  
lr_2_rec &amp;lt;-
  recipe(fml_2, data = df_train) %&amp;gt;% step_dummy(all_nominal(), -all_outcomes())  
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;logistic-regression-model-training&#34;&gt;Logistic regression model training&lt;/h3&gt;
&lt;p&gt;We train a logistic regression model and use five-fold cross-validation to
evaluate the model fit. Here we gonna use the recipe from earlier and that and
the model to &lt;code&gt;workflow&lt;/code&gt; which is handling the information so we easy can make
predictions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_mod &amp;lt;- logistic_reg() %&amp;gt;% set_engine(&amp;quot;glm&amp;quot;)
lr_wfl_1 &amp;lt;- workflow() %&amp;gt;% add_model(lr_mod) %&amp;gt;% add_recipe(lr_1_rec)
lr_wfl_2 &amp;lt;- workflow() %&amp;gt;% add_model(lr_mod) %&amp;gt;% add_recipe(lr_2_rec)
lr_wfls &amp;lt;- list(quay = lr_wfl_1, arriving_from = lr_wfl_2)

lr_fits_rs &amp;lt;-
  lr_wfls %&amp;gt;%
  imap(~ {
    fit_resamples(
      .x,
      resamples = df_train_folds,
      control = control_resamples(save_pred = TRUE)
    )
  })
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;rlang&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &#39;package:purrr&#39;:
## 
##     %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int,
##     flatten_lgl, flatten_raw, invoke, list_along, modify, prepend,
##     splice
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:magrittr&#39;:
## 
##     set_names
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;vctrs&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:tibble&#39;:
## 
##     data_frame
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:dplyr&#39;:
## 
##     data_frame
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ! Fold1: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-defici...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ! Fold2: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-defici...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ! Fold3: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-defici...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ! Fold4: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-defici...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ! Fold5: preprocessor 1/1, model 1/1 (predictions): prediction from a rank-defici...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the evaluation of the model fit we use the model &lt;em&gt;accuracy&lt;/em&gt; and the
&lt;em&gt;Receiver Operating characteristic (ROC)&lt;/em&gt; curve which plots the True Positive
Rate (the sensitivity) against the False Positive Rate (1 - specificity/true
negative rate). These measures are defined&lt;/p&gt;
&lt;p&gt;$$
&lt;code&gt;\begin{aligned} \mathrm{accuracy} &amp;amp;= \frac{\mathrm{TP} + \mathrm{TN}}{N} \\ \text{sensitivity} &amp;amp;= \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}} \\ \text{specificity} &amp;amp;= \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}} \end{aligned}&lt;/code&gt;
$$&lt;/p&gt;
&lt;p&gt;where &lt;code&gt;\(\mathrm{TP}\)&lt;/code&gt; is number of true WP (true positive), &lt;code&gt;\(\mathrm{TN}\)&lt;/code&gt; is the
number of true WC (true negative), &lt;code&gt;\(\mathrm{FN}\)&lt;/code&gt; is the number of predicted WCs
which really were WPs (false negative) and &lt;code&gt;\(\mathrm{FP}\)&lt;/code&gt; is the number of
falsely predicted WP vessels (false positive).&lt;/p&gt;
&lt;p&gt;The other measure we are gonna use is the &lt;em&gt;classification accuracy&lt;/em&gt;. It is
the fraction of predictions our model got right.&lt;/p&gt;
&lt;p&gt;Figure &lt;a href=&#34;#fig:lr-train-roc-curves&#34;&gt;1&lt;/a&gt; shows the trade-off between TRP and 1-FP.
Classifiers that give curves closer to the top-left corner indicate a better
performance. Here we see that some gives a perfect prediction.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits_rs %&amp;gt;%
  imap(~ {
    collect_predictions(.x) %&amp;gt;%
      group_by(id) %&amp;gt;%
      roc_curve(truth = cargo, .pred_WP) %&amp;gt;%
      autoplot() + ggtitle(.y) + theme_orsted(base_family = &amp;quot;&amp;quot;)
  }) %&amp;gt;%
  reduce(`+`)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/lr-train-roc-curves-1.svg&#34; alt=&#34;ROC curves.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure 1: ROC curves.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;As a final clearification we can look at Table &lt;a href=&#34;#tab:lr-train-mdl-accu&#34;&gt;1&lt;/a&gt;  that
shows us a clear picture of our cross validation and can conclude that we will
use quay af a predictor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits_rs %&amp;gt;%
  imap_dfr(~ relocate(mutate(collect_metrics(.x), model = .y), model)) %&amp;gt;%
  kbl(caption = &amp;quot;Model accuracy.&amp;quot;) %&amp;gt;% kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;caption&gt;Table 1: Model accuracy.&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; model &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; .metric &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; .estimator &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; mean &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; n &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; std_err &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; .config &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; accuracy &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; binary &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9377778 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0254830 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Preprocessor1_Model1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; roc_auc &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; binary &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9064931 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0552653 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Preprocessor1_Model1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; accuracy &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; binary &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.8556140 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0102995 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Preprocessor1_Model1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; roc_auc &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; binary &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.7748264 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0681452 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Preprocessor1_Model1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;prediction&#34;&gt;Prediction&lt;/h3&gt;
&lt;p&gt;Now that we have trained our model on the training data, we test how well it
does on the test data. We are os course certain that quay is the best predictor
but we are gonna show the result for both predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# FIXME prediction from a rank-deficient fit may be misleading. https://stackoverflow.com/a/26560328.
lr_fits &amp;lt;- lr_wfls %&amp;gt;% map(~ fit(., data = df_train))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits %&amp;gt;%
  imap(~ {
    predict(.x, df_test, type = &amp;quot;class&amp;quot;) %&amp;gt;%
      bind_cols(select(df_test, cargo)) %&amp;gt;%
      conf_mat(truth = cargo, estimate = .pred_class) %&amp;gt;%
      autoplot(type = &amp;quot;heatmap&amp;quot;) + ggtitle(.y)
  }) %&amp;gt;%
  reduce(`+`)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-14-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits %&amp;gt;%
  imap_dfr(~ {
    predict(.x, df_test, type = &amp;quot;prob&amp;quot;) %&amp;gt;% 
      bind_cols(select(df_test, cargo)) %&amp;gt;%
      roc_curve(truth = cargo, .pred_WP) %&amp;gt;%
      mutate(model = .y)
  }) %&amp;gt;%
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) + 
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) + 
  coord_equal() + 
  scale_color_orsted_d()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;/post/2021-01-07-cargo-classification/index.en_files/figure-html/unnamed-chunk-15-1.svg&#34; width=&#34;672&#34; /&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_pred_prob %&amp;gt;% roc_auc(truth = cargo, .pred_WP) %&amp;gt;%  kbl() %&amp;gt;% kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the above result we see that the quay as a predictor has correctly predicted
every data point in our test set.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;From our analysis we have created a logistic regression model that predicts if
the upcomming vessel is arriving with WP or WC to CMport.&lt;/p&gt;
&lt;p&gt;Our model is using &lt;code&gt;quay&lt;/code&gt; as a predictor and this give us good with a very high
accuracy.&lt;/p&gt;
&lt;h2 class=&#34;appendix&#34; id=&#34;estimation-results&#34;&gt;Estimation results&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits[[1]] %&amp;gt;% pull_workflow_fit() %&amp;gt;% tidy() %&amp;gt;% kbl(digits = 2) %&amp;gt;% kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; term &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; estimate &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; std.error &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; statistic &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; (Intercept) &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.01 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.10 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay_c836 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -1.56 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.45 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -1.08 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.28 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay_c837 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.41 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.26 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -3.49 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; quay_c838 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -6.61 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.45 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.56 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lr_fits[[2]] %&amp;gt;% pull_workflow_fit() %&amp;gt;% tidy() %&amp;gt;% kbl(digits = 2) %&amp;gt;% kable_styling()
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; term &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; estimate &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; std.error &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; statistic &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; p.value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; (Intercept) &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20.57 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10236.63 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Avedörevaerkets.Havn &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Bandholm..Maribo. &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 13541.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Bekkeri &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 14476.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Bremen.Farge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Cartagena &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Enstedvaerkets.Havn &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 16185.54 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Eydehavn &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 16185.54 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Gdynia &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 13541.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Gent &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 13541.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Greifswald..Landkreis &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 13541.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Grenå &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Huelva &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Köge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Larvik &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -19.87 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10236.63 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Leixoes &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Liepaja &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 11444.90 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Lübeck &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 11356.53 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Lyngdal &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Mandal &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Mersrags &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -20.57 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10236.63 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Papenburg &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Riga &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -19.55 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10236.63 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Rohukuela &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Rostock &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 13541.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Santana &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 16185.54 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Skulte &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 16185.54 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Stralsund &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 14476.79 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Szczecin &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Szczecinek &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; NA &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Tallinn &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 16185.54 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Törkopp..Drammen. &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Ventspils &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -19.18 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10236.63 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Virtsu &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Wismar &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.00 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Övriga.danska.hamnar &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; arriving_from_Övriga.estniska.hamnar &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -41.13 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20473.27 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;We never use a model&amp;rsquo;s fit to the training set to evaluate the
model&amp;rsquo;s performance.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nøie review analysis from Trustpilot</title>
      <link>/post/test/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/post/test/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Trustpilot is a site where user can give a review of different products.
The reviews can reveal some essentiel details about the products and
service. This can be beneficial for the company to track and analysis
the reviews. When there is a lot of reviews it can be hard to keep
track of the information. Therefore NPL can be useful in such
circumstances.&lt;/p&gt;
&lt;p&gt;As an example I am gonna use the Nøie reviews to build a topic model to see
what is the genreal topics for good and bad reviews.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;web-scraping&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Web scraping&lt;/h2&gt;
&lt;p&gt;For scraping the &lt;a href=&#34;https://www.trustpilot.com/review/noie.com&#34;&gt;trutpilot site&lt;/a&gt;
I am gonna use the browser chrome to look behind the site to look for what
data I need to scrape:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;chrome_site.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is multiple pages of reviews so I am gonna make some general functions
to extract the following variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;get_ratings&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;get_reviews&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;get_reviewer_names&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and combine it into a tibble with &lt;code&gt;get_data&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_ratings &amp;lt;- function(html) {
  html %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(&amp;quot;body&amp;quot;) %&amp;gt;%
    html_nodes(&amp;quot;.star-rating&amp;quot;) %&amp;gt;%
    as.character() %&amp;gt;%
    str_subset(&amp;quot;medium&amp;quot;) %&amp;gt;%
    str_extract(&amp;quot;(\\d stjerne)&amp;quot;) %&amp;gt;%
    str_remove((&amp;quot;( stjerne)&amp;quot;)) %&amp;gt;%
    unlist()
}

get_reviews &amp;lt;- function(html) {
  html %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(&amp;quot;.review-content__body&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    str_trim() %&amp;gt;%
    unlist()
}

get_reviewer_names &amp;lt;- function(html) {
  html %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(&amp;quot;.consumer-information__name&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    str_trim() %&amp;gt;%
    unlist()
}

get_data &amp;lt;- function(html) {
  review &amp;lt;- get_reviews(html)
  names &amp;lt;- get_reviewer_names(html)
  ratings &amp;lt;- get_ratings(html)
  data &amp;lt;- tibble(
    reviewer = names,
    rating = ratings,
    review = review
  )
  return(data)
}

urls &amp;lt;- cbind(c(url1, url2, url3, url4, url5, url6, url7))

url_list &amp;lt;- map(urls, get_data) %&amp;gt;%
  as.list()

data &amp;lt;- do.call(bind_rows, url_list)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;reviewer&lt;/code&gt; the user of the product.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rating&lt;/code&gt; what the reviewer has chosen to give the product on a
scale from 1-5.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;review&lt;/code&gt; is the comment given by the reviewer and the central aspect
for this analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before we can begin the modelling process we need to preprocess the data.
When dealing with unstructred data such as text data the modeller need to
use a great amount of time for making the data ready.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;loading-and-preparing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Loading and preparing the data&lt;/h2&gt;
&lt;p&gt;From the data we can see that the reviews are in Danish. Here we can use
the &lt;code&gt;happyorsad&lt;/code&gt; package to compute a sentiment score for each review.
The scores are based on a Danish list of sentiment words and put
toheather by
&lt;a href=&#34;https://www.dtu.dk/service/telefonbog/person?id=1755&amp;amp;cpid=&amp;amp;tab=1&#34;&gt;Finn Årup Nielsen&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We are also going to remove numbers, punctuation and stopwords.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;-
  data %&amp;gt;%
  mutate(sentiment = map_int(review, happyorsad, &amp;quot;da&amp;quot;)) %&amp;gt;%
  mutate(review = tolower(review)) %&amp;gt;%
  mutate(
    review = removeWords(
      review,
      c(
        &amp;quot;så&amp;quot;, &amp;quot;lidt&amp;quot;, &amp;quot;virkelig&amp;quot;,
        &amp;quot;virkelig&amp;quot;, &amp;quot;fuldstændig&amp;quot;, &amp;quot;helt&amp;quot;, &amp;quot;mere&amp;quot;,
        &amp;quot;kan&amp;quot;, &amp;quot;få&amp;quot;, &amp;quot;får&amp;quot;, &amp;quot;fik&amp;quot;, &amp;quot;nøie&amp;quot;,
        &amp;quot;altså&amp;quot;, &amp;quot;gav&amp;quot;, &amp;quot;endnu&amp;quot;,
        &amp;quot;sagde&amp;quot;, &amp;quot;ingen&amp;quot;, &amp;quot;flere&amp;quot;,
        stopwords(&amp;quot;danish&amp;quot;)
      )
    ),
    review = removeNumbers(review)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;distribution-of-sentiment-scores&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distribution of sentiment scores&lt;/h2&gt;
&lt;p&gt;In the density plot we see how sentiment scores are distributed with a
median score of 8. This a really good score and it is of interst to find
out &lt;em&gt;why&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;%
  ggplot(aes(x = sentiment)) +
  geom_density(size = 1) +
  geom_vline(
    xintercept = median(df$sentiment),
    colour = &amp;quot;indianred&amp;quot;, linetype = &amp;quot;dashed&amp;quot;, size = 1
  ) +
  annotate(&amp;quot;text&amp;quot;,
    x = 15, y = 0.06, label = paste(
      &amp;quot;median = &amp;quot;,
      median(df$sentiment)
    ),
    colour = &amp;quot;indianred&amp;quot;
  ) +
  my_theme() +
  xlim(-40, 40)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-01-02-test/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In a crude way we can put positive and negative reviews in separate data
frames perform topic modelling on each in order to explore what
reviewers lik and dislike.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;topic-modelling-for-positive-reviews&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Topic modelling for positive reviews&lt;/h2&gt;
&lt;p&gt;I start with the positive reviews where I am going to tokenized the data frame
which mean one is going to break the text into words so every words can be
analyze individually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_pos &amp;lt;-
  df %&amp;gt;%
  filter(sentiment &amp;gt; 1) %&amp;gt;%
  unnest_tokens(word, review) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremen&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremer&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremejeg&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremene&amp;quot;, &amp;quot;creme&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before creating a so called &lt;strong&gt;document term matrix&lt;/strong&gt; we need to count
the frequency of each word per document.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words_pos &amp;lt;- df_pos %&amp;gt;%
  count(reviewer, word, sort = TRUE) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to use the famouse &lt;code&gt;Latent Dirichlet Allocation&lt;/code&gt; algorithme for
Topic modelling. To use this we need to create our DTM and here we use
&lt;code&gt;tidytext&lt;/code&gt; function &lt;code&gt;cast_dtm&lt;/code&gt; to do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reviewDTM_pos &amp;lt;- words_pos %&amp;gt;%
  cast_dtm(reviewer, word, n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;LDA assumes that every document is a mixture of topics, and every topic
is a mixture of words. The &lt;code&gt;k&lt;/code&gt; argument is used to specify the desired
amount of topics that we want in our model. Let´s create a two-topic
mode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reviewLDA_pos &amp;lt;- LDA(reviewDTM_pos, k = 2, control = list(seed = 123))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following table shows how many reviews that are assigned to each
topic&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(topics(reviewLDA_pos)) %&amp;gt;%
  group_by(`topics(reviewLDA_pos)`) %&amp;gt;%
  count() %&amp;gt;%
  kable(col.names = c(&amp;quot;Positive reviews&amp;quot;, &amp;quot;#&amp;quot;)) %&amp;gt;%
  kable_styling(
    full_width = FALSE,
    position = &amp;quot;left&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; &#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Positive reviews
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
#
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
52
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
57
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is also possible to get the per-topic word probabilities or ‘beta’&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;topics_pos &amp;lt;- tidy(reviewLDA_pos, matrix = &amp;quot;beta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can find the words with the highest beta. Here we choose the top
five words which we will show in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;top_terms_pos &amp;lt;- topics_pos %&amp;gt;%
  group_by(topic) %&amp;gt;%
  top_n(5, beta) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(topic, -beta) %&amp;gt;%
  mutate(order = rev(row_number()))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;topic-modelling-for-negative-reviews&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Topic modelling for negative reviews&lt;/h2&gt;
&lt;p&gt;Let us see what can be said regarding the negativ reviews where the
sentiment score is below -1&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_neg &amp;lt;-
  df %&amp;gt;%
  filter(sentiment &amp;lt; -1) %&amp;gt;%
  unnest_tokens(word, review) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremen&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremer&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremejeg&amp;quot;, &amp;quot;creme&amp;quot;)) %&amp;gt;%
  mutate(word = str_replace(word, &amp;quot;cremene&amp;quot;, &amp;quot;creme&amp;quot;))

words_neg &amp;lt;- df_neg %&amp;gt;%
  count(reviewer, word, sort = TRUE) %&amp;gt;%
  ungroup()

reviewDTM_neg &amp;lt;- words_neg %&amp;gt;%
  cast_dtm(reviewer, word, n)

reviewLDA_neg &amp;lt;- LDA(reviewDTM_neg, k = 2, control = list(seed = 347))

tibble(topics(reviewLDA_neg)) %&amp;gt;%
  group_by(`topics(reviewLDA_neg)`) %&amp;gt;%
  count() %&amp;gt;%
  kable(col.names = c(&amp;quot;Negative reviews&amp;quot;, &amp;quot;#&amp;quot;)) %&amp;gt;%
  kable_styling(full_width = FALSE, position = &amp;quot;left&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table&#34; style=&#34;width: auto !important; &#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Negative reviews
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
#
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;topics_neg &amp;lt;- tidy(reviewLDA_neg, matrix = &amp;quot;beta&amp;quot;)

topTerms_neg &amp;lt;- topics_neg %&amp;gt;%
  group_by(topic) %&amp;gt;%
  top_n(5, beta) %&amp;gt;%
  ungroup() %&amp;gt;%
  arrange(topic, -beta) %&amp;gt;%
  mutate(order = rev(row_number()))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-topic-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the topic models&lt;/h2&gt;
&lt;p&gt;Now what the models are on made we can make a plot to make a comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_pos &amp;lt;-
  top_terms_pos %&amp;gt;%
  ggplot(aes(order, beta)) +
  ggtitle(&amp;quot;Positive review topics&amp;quot;) +
  geom_col(show.legend = FALSE, fill = &amp;quot;steelblue&amp;quot;) +
  scale_x_continuous(
    breaks = top_terms_pos$order,
    labels = top_terms_pos$term,
    expand = c(0, 0)
  ) +
  facet_wrap(~topic, scales = &amp;quot;free&amp;quot;) +
  coord_flip(ylim = c(0, 0.02)) +
  my_theme() +
  theme(axis.title = element_blank())

plot_neg &amp;lt;- topTerms_neg %&amp;gt;%
  ggplot(aes(order, beta, fill = factor(topic))) +
  ggtitle(&amp;quot;Negative review topics&amp;quot;) +
  geom_col(show.legend = FALSE, fill = &amp;quot;indianred&amp;quot;) +
  scale_x_continuous(
    breaks = topTerms_neg$order,
    labels = topTerms_neg$term,
    expand = c(0, 0)
  ) +
  facet_wrap(~topic, scales = &amp;quot;free&amp;quot;) +
  coord_flip(ylim = c(0, 0.02)) +
  my_theme() +
  theme(axis.title = element_blank())

grid.arrange(plot_pos, plot_neg, ncol = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-01-02-test/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So with the above plots we get a feeling on what the reviewer like and dislike
regarding Nøie product and brand.&lt;/p&gt;
&lt;p&gt;As a general notice we are dealing with a really small dataset so this give
us some touble sepecially for the negative reviews where there is fewer (a good
sign for Nøie).&lt;/p&gt;
&lt;p&gt;Looking for the positive reviews:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;em&gt;creme&lt;/em&gt; gives a nice skin and the service is really great.&lt;/li&gt;
&lt;li&gt;The producs is good and give a super skin.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As mention the problem with the nagative reviews is the sparsity of data.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The creme gives impurities and zits.&lt;/li&gt;
&lt;li&gt;Some reviewer think the marketing is bad.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Interestingly, customers seem to have both positive and negative experiences with
respect to pretty much the same topics. Some customers appear to experience good
result from the creme, whereas others seem to complain.&lt;/p&gt;
&lt;p&gt;This can be explored further.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;word-co-occurrence-within-reviews&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Word co-occurrence within reviews&lt;/h2&gt;
&lt;p&gt;To see whether word paris like “bad creame” and “good creme” are
frequent in the data sets, we´ll count how many times each pair of words
occurs togeather in a title or description field. This can easy be done
with &lt;code&gt;pairwise_count()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;word_pairs_pos &amp;lt;- df_pos %&amp;gt;%
  pairwise_count(word, reviewer, sort = TRUE)

word_pairs_neg &amp;lt;- df_neg %&amp;gt;%
  pairwise_count(word, reviewer, sort = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then plot the most common word pairs co-occurring in the reviews
by means of the &lt;code&gt;igraph&lt;/code&gt; and &lt;code&gt;ggraph&lt;/code&gt; packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pair_wise_helper &amp;lt;- function(data, title, color) {
  data %&amp;gt;%
    graph_from_data_frame() %&amp;gt;%
    ggraph(layout = &amp;quot;fr&amp;quot;) +
    geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = color) +
    ggtitle(title) +
    geom_node_point(size = 5) +
    geom_node_text(aes(label = name),
      repel = TRUE,
      point.padding = unit(0.2, &amp;quot;lines&amp;quot;)
    ) +
    my_theme() +
    theme(
      axis.title = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank()
    )
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pairs_plot_pos &amp;lt;-
  pair_wise_helper(
    word_pairs_pos %&amp;gt;% filter(n &amp;gt;= 15),
    &amp;quot;Positive word pairs&amp;quot;,
    &amp;quot;steelblue&amp;quot;
  )

pairs_plot_neg &amp;lt;-
  pair_wise_helper(
    word_pairs_neg %&amp;gt;% filter(n &amp;gt; 2),
    &amp;quot;Negative word pairs&amp;quot;,
    &amp;quot;indianred&amp;quot;
  )

grid.arrange(pairs_plot_pos, pairs_plot_neg, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-01-02-test/index.en_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the positive reviews, it is clear that the word for “creme” tends to co-occur
with the word for “hud” and “god”. In the negative reviews, we can se there is
not enough data for making any clearness regarding the co-occurance of words.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;word-pair-correlations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Word pair correlations&lt;/h2&gt;
&lt;p&gt;Aanother interesting idea is to measure the correlation for specific
words. Here I only look at the positiv dataset because there are to few
observation in the negative one.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As an alternative idea is to perform an n-gram analysis to find out
which words most frequently are used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_pos &amp;lt;-
  df_pos %&amp;gt;%
  group_by(word) %&amp;gt;%
  filter(n() &amp;gt;= 10) %&amp;gt;%
  pairwise_cor(word, reviewer, sort = TRUE) %&amp;gt;%
  filter(item1 == &amp;quot;creme&amp;quot;) %&amp;gt;%
  top_n(7) %&amp;gt;%
  mutate(
    item1 = as.factor(item1),
    order = rev(row_number())
  )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor_pos %&amp;gt;%
  ggplot(aes(x = order, y = correlation, fill = item1)) +
  geom_col(show.legend = FALSE) +
  scale_x_continuous(
    breaks = cor_pos$order,
    labels = cor_pos$item2,
    expand = c(0, 0)
  ) +
  scale_fill_manual(values = c(&amp;quot;steelblue&amp;quot;, &amp;quot;indianred&amp;quot;)) +
  coord_flip() +
  labs(x = &amp;quot;words&amp;quot;) +
  my_theme()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-01-02-test/index.en_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The analysis confirm that Nøie has a very high custumer satisfication.
The customer are describing the producted to delivered what they want
and the service is very satisfiying.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Master of tidyverse</title>
      <link>/project/master_of_the_tidyverse/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/project/master_of_the_tidyverse/</guid>
      <description>&lt;p&gt;In the course &amp;ldquo;Introduction to data science&amp;rdquo; which is about learning essentiel
tools for a data scientist including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plotting&lt;/li&gt;
&lt;li&gt;manipulate data&lt;/li&gt;
&lt;li&gt;regular expressions&lt;/li&gt;
&lt;li&gt;modelling&lt;/li&gt;
&lt;li&gt;explanatory data analysis&lt;/li&gt;
&lt;li&gt;retional database&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here we had an contest in finding a data set and show wha you have learn. I
my an analysis of gas emission and showed analysis the market and which contries
contributed the most to the emission.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ørsted Classification model</title>
      <link>/project/%C3%B8rsted-classification/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/project/%C3%B8rsted-classification/</guid>
      <description>&lt;p&gt;At Ørsted we had a problem with cargoes comming from around the word to
Amagerværket. The cargoes could either carry Wood Pellets or Wood Chips. It
was every important for the team to know what each cargo were carrying.&lt;/p&gt;
&lt;p&gt;For solving this problem I found data from scraping the net and made a Machine
Learning model that classified each cargo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Did QE effect the economics</title>
      <link>/project/qe/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/qe/</guid>
      <description>&lt;p&gt;After the financial crisis the world economics saw it self in the deepest
recessions since 1939. For comming out of this crisis the Euopean Central Bank (ECB)
tried a alternative tool called Quantitative easing. It was implementet as
a way to secure price stability which is ECB main agenda. In this analysis I
try to quantify weather they made their goal and as a side effect managed to
lift the economics. By measuring this I am using a vector autoregressiv (VAR)
model.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tidymodels, Random Forest og parsnip</title>
      <link>/post/tidymodels-and-parsnip/</link>
      <pubDate>Mon, 17 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/tidymodels-and-parsnip/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduktion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduktion&lt;/h2&gt;
&lt;p&gt;I denne post vil jeg kigger på to modeller.
Den &lt;strong&gt;logistiske regression&lt;/strong&gt; og &lt;strong&gt;random forest&lt;/strong&gt;, hvor de begge bliver brugtblog
som klassifikations modeller.&lt;/p&gt;
&lt;p&gt;Jeg kommer til at gennemgå og beskrive Random Forest da det er en model,
som er forholdsvis ny for mig og der er nogle teoretiske framwork jeg gerne
vil prøve at forklare.&lt;/p&gt;
&lt;p&gt;Desuden kommer vi til at stifte bekendtskab med &lt;code&gt;parsnip&lt;/code&gt; som gør det let at
skifte om til de forskellige modeller. Med det nye framwork fra
&lt;code&gt;tidymodels&lt;/code&gt; kan man skifte utrolig let fra &lt;code&gt;glm&lt;/code&gt; til en &lt;strong&gt;cross validated&lt;/strong&gt;
random forest med &lt;code&gt;ranger&lt;/code&gt;
med få linjers koder.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random-forest&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Random forest&lt;/h2&gt;
&lt;p&gt;Det er en af de mest populære machine learning algoritmer og kan både bruges
som en regresssion og klassifikation model.&lt;/p&gt;
&lt;p&gt;Som navnet antyder så laver algoritmen en skov med forskellige beslutningstræer.
Desto flere træer desto mere robust er modellen. Navnet random kommer grundet to koncepter&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Et randomiseret sample af trænings data, når man bygger hver enkelt træ.&lt;/li&gt;
&lt;li&gt;Et randomiseret subsæt af features, når man splitter noder.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Når vi træer hver træ så lærer den fra et random sample af data punkter.
Samples er trukket med erstatning, som kaldes &lt;strong&gt;bootstrapping&lt;/strong&gt;, som betyder
at et sample vil blive brugt flere gange i et enkelt træ. Ideen er at ved at
træne hver træ med forskellige samples, så vil vi få en lavere varians og
ikke få et højere bias.&lt;/p&gt;
&lt;p&gt;Ens prediction fås ved at tage gennmsnittet af predictor for hver beslutningstræ.
Denne procedure kaldes for &lt;strong&gt;bagging&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Fordele er man kan bruge den som klassifikation og regression. Den vil ikke overfitte.
Den kan håndtere store datasæt med mange dimensioner.&lt;/p&gt;
&lt;p&gt;Ulemper er den ikke er så god til regressioner. Den er ikke god til at forudsige.
Der er heller ikke meget kontrol over modellen.&lt;/p&gt;
&lt;p&gt;Dog er modellen anvendelig i mange sektor såsom banker, forsikringsselskaber,
forretninger somkan bruges til at finde de loyolae kunder. Den kan også bruges i
aktiemarkedet til ast finde opførelsen af en aktie.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;I dette projekt bruger jeg data
fra Telco Customer Churn. Data indeholder 7043 rækker som hver repræsentere en kunde.
Der er 21 kolonner som er mulige predictor, der giver information til vi kan
forecast opførelse og give indsigt på forebyggelsesprogrammer.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Churn&lt;/code&gt; er den afhængige variable og viser om kunden har forladt virksomheden
indenfor den seneste måned.&lt;/p&gt;
&lt;p&gt;Jeg bruger funnktionen &lt;code&gt;skim&lt;/code&gt; til at skabe et overblik over mit data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;telco &amp;lt;- readr::read_csv(&amp;quot;https://raw.githubusercontent.com/treselle-systems/customer_churn_analysis/master/WA_Fn-UseC_-Telco-Customer-Churn.csv&amp;quot;)
telco %&amp;gt;% 
  skimr::skim()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;Data summary&lt;/caption&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Name&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Piped data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Number of rows&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7043&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Number of columns&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;21&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;_______________________&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Column type frequency:&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;character&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;numeric&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;________________________&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Group variables&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;None&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Variable type: character&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;skim_variable&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_missing&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;complete_rate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;min&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;max&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;empty&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_unique&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;whitespace&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;customerID&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7043&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;gender&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Partner&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Dependents&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PhoneService&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;MultipleLines&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;InternetService&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;OnlineSecurity&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;OnlineBackup&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;DeviceProtection&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TechSupport&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;StreamingTV&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;StreamingMovies&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Contract&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PaperlessBilling&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PaymentMethod&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Churn&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Variable type: numeric&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;skim_variable&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_missing&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;complete_rate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sd&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p25&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p50&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p75&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p100&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;hist&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;SeniorCitizen&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.37&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;▇▁▁▁▂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;tenure&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32.37&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.56&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.00&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;▇▃▃▃▆&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;MonthlyCharges&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;64.76&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30.09&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;70.35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;89.85&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;118.75&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;▇▅▆▇▅&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TotalCharges&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2283.30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2266.77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18.80&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;401.45&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1397.47&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3794.74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8684.80&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;▇▂▂▂▁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Her er en række ting at lægge mærke til her.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;customerID&lt;/strong&gt; er en unik id for hver række og af den grund har den ingen
deskriptiv eller predictive power og den skal fjernes.&lt;/li&gt;
&lt;li&gt;Der er meget få &lt;strong&gt;NA&lt;/strong&gt; værdier, så de kan jeg tillade mig at slette.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;telco &amp;lt;- telco %&amp;gt;% 
  select(-customerID) %&amp;gt;% 
  drop_na()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;modellering-med-tidymodels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modellering med &lt;code&gt;tidymodels&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Denne post giver også en introduktion til tidymodels. Derfor vil modellen
være simpel og kommer til at bestå af &lt;strong&gt;logistic regression&lt;/strong&gt; model uden meget
data bearbejdring.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;train-and-test-split&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Train and test split&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;rsample()&lt;/code&gt; kan bruges til at lave en randomiserede træning og test data,
som selvfølgelig er konstrueret udfra vores orginale telco data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1972)

train_test_split &amp;lt;- rsample::initial_split(
  data = telco,
  prop = 0.8
)
train_test_split&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;Analysis/Assess/Total&amp;gt;
## &amp;lt;5626/1406/7032&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ud fra ovenstående har vi at de 7032 kunder er blevet delt ud, og de 5626 er blevet
sat i træningssættet. Vi gemmer dem ned i deres eget data frame;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_tbl &amp;lt;- train_test_split %&amp;gt;% training() %&amp;gt;% 
  unnest()
test_tbl &amp;lt;- train_test_split %&amp;gt;% testing()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;en-bage-opskrift&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;En bage opskrift&lt;/h2&gt;
&lt;p&gt;For at lave en del af arbejde for at bygge modellen bruger vi &lt;code&gt;recipe()&lt;/code&gt;. Denne
pakke bruger &lt;em&gt;bage metafor&lt;/em&gt; til at behandle data og foretage diverse præprocessor
såsom, missing values, fjerne predictor, centering og scaling osv..&lt;/p&gt;
&lt;p&gt;Det første man gør er at definere &lt;code&gt;recipe&lt;/code&gt; og de transformationer man vil bruge
på ens data. Der er ikke meget at gøre i dette tilfælde, udover at tranaformerer
til faktor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;recipe_simple &amp;lt;- function(dataset) {
  recipe(Churn ~ ., data = dataset) %&amp;gt;% 
    step_string2factor(all_nominal(), -all_outcomes()) %&amp;gt;% 
    prep(data = dataset)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For at undgår man vi har en &lt;strong&gt;data lækage&lt;/strong&gt; (oveføre information mellem træning
og test data), skal data være ‘prepped’ ved
kun at bruge &lt;code&gt;train_tbl&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;recipe_prepped &amp;lt;- recipe_simple(dataset = train_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Som den sidste del så skal vi &lt;em&gt;bage opskriften&lt;/em&gt; for at alle præprocessor
bliver inkluderet i data sættene.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;train_baked &amp;lt;- bake(recipe_prepped, new_data = train_tbl)
test_baked &amp;lt;- bake(recipe_prepped, new_data = test_tbl)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-modellen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit modellen&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Tidymodels&lt;/code&gt; er det helt nye indspark fra tidyverse folkene på at skabe et framwork
for machine learning.
Hertil er der blevet lavet en del justeringer og nye pakker. En central pakke i
dette framwork er &lt;code&gt;parsnip&lt;/code&gt;,som skaber en adgang til mange machine learning pakker
uden man skal kunne syntaksen til dem alle.&lt;/p&gt;
&lt;p&gt;Man skal følge tre trin:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Bestem &lt;strong&gt;typen af modellen&lt;/strong&gt; og &lt;strong&gt;mode&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Bestem &lt;strong&gt;engine&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Bestem model specifikationer og data der skal bruges.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logistic_glm &amp;lt;- logistic_reg(mode = &amp;quot;classification&amp;quot;) %&amp;gt;% 
  set_engine(&amp;quot;glm&amp;quot;) %&amp;gt;% 
  fit(Churn ~ .,
      data = train_baked)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Som sagt så kan du vælge en masse andre engine. I dette tilfælde hvor vi bruge en
logistisk regression, så kan vi vælge; &lt;code&gt;glm&lt;/code&gt;, &lt;code&gt;glmnet&lt;/code&gt;, &lt;code&gt;stan&lt;/code&gt;, &lt;code&gt;spark&lt;/code&gt; og &lt;code&gt;keras&lt;/code&gt;.
Det smarte er vi bare kan skifte det ud og så klare parsnip transitionen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hvor-godt-klare-modellen-sig&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hvor godt klare modellen sig?&lt;/h2&gt;
&lt;p&gt;Det er væsentlig at se hvor god modellen er og her bruger vi pakken
&lt;code&gt;yardstick&lt;/code&gt;, som gør det let at beregne forskellige måleværktøjer.
Før man kan beregne disse måle enheder skal vi beregne nogle
predictor ved at bruge &lt;code&gt;test_baked&lt;/code&gt; til predict funktionen.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prediction_glm &amp;lt;- logistic_glm %&amp;gt;% 
  predict(new_data = test_baked) %&amp;gt;%
  bind_cols(test_baked %&amp;gt;%  select(Churn))

head(prediction_glm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   .pred_class Churn
##   &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;
## 1 Yes         No   
## 2 No          No   
## 3 No          No   
## 4 No          No   
## 5 No          No   
## 6 No          No&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der kan benyttes mange matricer til at undersøge hvor god modellen er,
men fokus for denne post bliver &lt;strong&gt;accuracy&lt;/strong&gt;, &lt;strong&gt;precision&lt;/strong&gt;, &lt;strong&gt;recall&lt;/strong&gt; og &lt;strong&gt;F1_score&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Disse mål bliver udledt af &lt;strong&gt;Confusion Matrix&lt;/strong&gt;, som er en tabel der beskriver
hvor godt ens klassifikations model klarer sig. Denne matrice er i sig selv ikke svær at
forstå, da den angiver antallet af; &lt;em&gt;false positives&lt;/em&gt;, &lt;em&gt;false negatives&lt;/em&gt;, &lt;em&gt;true positives&lt;/em&gt;
og &lt;em&gt;true negatives&lt;/em&gt;. Dog er nogle af målene, som udledes herfra svære koncepter og kræver
reflektion for at forstå deres betydning.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prediction_glm %&amp;gt;% 
  conf_mat(Churn, .pred_class) %&amp;gt;% 
  pluck(1) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = &amp;quot;white&amp;quot;, alpha = 0.5, size = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-01-17-tidymodels-and-parship/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;2400&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Modellen &lt;strong&gt;Accuracy&lt;/strong&gt; er andel af prediction modellen ramte plet og kan udregnes ved at
lade predictions_glm gå gennem metrics funktionen. Dog er den ikke så troværdig, hvis
ens data er ubalanceret.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prediction_glm %&amp;gt;% 
  metrics(Churn, .pred_class) %&amp;gt;% 
  select(-.estimator) %&amp;gt;% 
  filter(.metric == &amp;quot;accuracy&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   .metric  .estimate
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;
## 1 accuracy     0.806&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Modellen får altså en score på 78%.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; målser hvor sensitiv modellen er overfor False Positive, mens
Recall ser hvor sensitiv modellen er for False Negative.&lt;/p&gt;
&lt;p&gt;Disse metricer er meget vigtig informationer for virksomheder fordi man så kan
forudsige hvilke kunder der er i en risiko gruppe for at forlade forretningen.
Herfra kan man så benytte sig af en fastholdessstrategi. Desuen kan
man bruge oplysning til ikke at bruge penge på kudner der alligevel
har tænkt sig at forlade virksomheden.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(
  &amp;quot;precision&amp;quot; =
    precision(prediction_glm, Churn, .pred_class) %&amp;gt;% 
    select(.estimate),
  &amp;quot;recall&amp;quot; =
    recall(prediction_glm, Churn, .pred_class) %&amp;gt;% 
    select(.estimate)
) %&amp;gt;% 
  unnest() %&amp;gt;% 
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;precision&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;recall&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.8466368&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9024857&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Den anden og sidste populær måleværktøj er F1_score, som er det harmoniske gennemsnit
af precision og recall. Den perfekte score på 1 fås når precision og recall er perfekte.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prediction_glm %&amp;gt;%
  f_meas(Churn, .pred_class) %&amp;gt;%
  select(-.estimator) %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;.metric&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;.estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;f_meas&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8736696&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;fra-logitstik-regression-til-random-forest&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fra logitstik regression til Random Forest&lt;/h2&gt;
&lt;p&gt;Det er utrolig simpel at skifte ens model ud med en anden. Den tidligere
anvendte logistisk regressions model kan vi hurtig skifte ud med en &lt;strong&gt;Random
Forest&lt;/strong&gt; model med &lt;code&gt;ranger&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;croos-validation-sæt-op&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Croos validation sæt op&lt;/h2&gt;
&lt;p&gt;For at styke modellens prediktive kræft kan man foretage cross validation, som
tit bliver sat op med 10 folder. Det kan implementeres med &lt;code&gt;vfold_cv()&lt;/code&gt; fra &lt;code&gt;rsample&lt;/code&gt;,
som splitter det initale trænings data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
cross_val_tbl &amp;lt;- 
   vfold_cv(train_tbl, v = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vi kan genkende de 5626 fra vores tærningssæt. I hver runde vil 563 observationer
blive brugt til validere modellen for det specifikke fold.&lt;/p&gt;
&lt;p&gt;For at ikke blive forvirret over bruget af initial træsning/test split til det
man bruger i cross validation benytter man begreberne &lt;code&gt;analysis&lt;/code&gt; (estimer modellen)
og &lt;code&gt;assessment&lt;/code&gt; (valider estimater).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;opdater-recipe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Opdater recipe&lt;/h2&gt;
&lt;p&gt;For at bruge Random Forest skal alle numeriske værdier være centred og scaled
og alle faktor skal være dummies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;split &amp;lt;- initial_split(telco, prop = 0.8)
train_data &amp;lt;- training(split)
test_data &amp;lt;- testing(split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For at skifte over til en anden model er utroligt simepel. Her ændre vi til
random forest i typen af modellen og tilføjer dens hyperparameter.&lt;/p&gt;
&lt;p&gt;For at gøre processen lidt hurtigere propper jeg det hele i en funktion, som
estimer modellen på tværs af alle folder og retuner det i en tibble. Desuden skal
der tilføjes et skridt mere for at vi mapper de forskellige folder.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;recipe_rf &amp;lt;- function(dataset) {
  recipe(Churn ~ ., data = dataset) %&amp;gt;%
    step_string2factor(all_nominal(), -all_outcomes()) %&amp;gt;%
    step_dummy(all_nominal(), -all_outcomes()) %&amp;gt;%
    step_center(all_numeric()) %&amp;gt;%
    step_scale(all_numeric()) %&amp;gt;%
    prep(data = dataset)
}

rf_fun &amp;lt;- function(split, id, try, tree) {
   
  analysis_set &amp;lt;- split %&amp;gt;% analysis()
  analysis_prepped &amp;lt;- analysis_set %&amp;gt;% recipe_rf()
  analysis_baked &amp;lt;- analysis_prepped %&amp;gt;% bake(new_data = analysis_set)
  model_rf &amp;lt;-
    rand_forest(
      mode = &amp;quot;classification&amp;quot;,
      mtry = try,
      trees = tree
    ) %&amp;gt;%
    set_engine(&amp;quot;ranger&amp;quot;,
      importance = &amp;quot;impurity&amp;quot;
    ) %&amp;gt;%
    fit(Churn ~ ., data = analysis_baked)
  assessment_set &amp;lt;- split %&amp;gt;% assessment()
  assessment_prepped &amp;lt;- assessment_set %&amp;gt;% recipe_rf()
  assessment_baked &amp;lt;- assessment_prepped %&amp;gt;% bake(new_data = assessment_set)
  tibble(
    &amp;quot;id&amp;quot; = id,
    &amp;quot;truth&amp;quot; = assessment_baked$Churn,
    &amp;quot;prediction&amp;quot; = model_rf %&amp;gt;%
      predict(new_data = assessment_baked) %&amp;gt;%
      unlist()
  )
  
}

pred_rf &amp;lt;- map2_df(
  .x = cross_val_tbl$splits,
  .y = cross_val_tbl$id,
  ~ rf_fun(split = .x, id = .y, try = 3, tree = 200)
)
head(pred_rf)  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   id     truth prediction
##   &amp;lt;chr&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;     
## 1 Fold01 Yes   No        
## 2 Fold01 Yes   Yes       
## 3 Fold01 No    No        
## 4 Fold01 No    No        
## 5 Fold01 No    No        
## 6 Fold01 No    No&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pred_rf %&amp;gt;%
  conf_mat(truth, prediction) %&amp;gt;%
  summary() %&amp;gt;%
  select(-.estimator) %&amp;gt;%
  filter(.metric %in%
    c(&amp;quot;accuracy&amp;quot;, &amp;quot;precision&amp;quot;, &amp;quot;recall&amp;quot;, &amp;quot;f_meas&amp;quot;)) %&amp;gt;%
  kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;.metric&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;.estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;accuracy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7996801&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;precision&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8291502&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;recall&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9147437&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;f_meas&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8698464&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Der er mange matricer til at validere vores model, men vi bruger dem som vi brugte
ved vores logistisk regression.&lt;/p&gt;
&lt;p&gt;Modellen klare sig på lige fod med regressionsmodellen. Man kunne gå tilbage til modellen
og laver yderligere feature eengierning da det ville gøre noget for selve
præcisionen af modellen.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt;
 | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;
: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Landing Page</title>
      <link>/contact/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/project_landing/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/project_landing/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
